nohup: ignoring input
batch: 0   train loss: 1.7694423198699951
batch: 1   train loss: 0.0
batch: 2   train loss: 36.91865158081055
batch: 3   train loss: 0.0
batch: 4   train loss: 9.364969253540039
batch: 5   train loss: 1.7435529232025146
batch: 6   train loss: 1.916199803352356
batch: 7   train loss: 2.424424648284912
batch: 8   train loss: 1.96449613571167
batch: 9   train loss: 1.4578670263290405
batch: 10   train loss: 0.9797708988189697
batch: 11   train loss: 0.7141211032867432
batch: 12   train loss: 0.6020546555519104
batch: 13   train loss: 1.0322818756103516
batch: 14   train loss: 1.013570785522461
batch: 15   train loss: 0.9195197820663452
batch: 16   train loss: 0.5619140863418579
batch: 17   train loss: 0.6234028935432434
batch: 18   train loss: 0.6393979787826538
batch: 19   train loss: 0.5683066844940186
batch: 20   train loss: 0.8629916906356812
batch: 21   train loss: 0.9715632796287537
batch: 22   train loss: 0.8828562498092651
batch: 23   train loss: 0.5565943717956543
batch: 24   train loss: 0.7455000281333923
batch: 25   train loss: 0.6868430972099304
batch: 26   train loss: 0.5453892350196838
batch: 27   train loss: 0.6085182428359985
batch: 28   train loss: 0.4355370104312897
batch: 29   train loss: 0.4521964192390442
batch: 30   train loss: 0.42312416434288025
batch: 31   train loss: 1.2272908687591553
batch: 32   train loss: 0.2831593453884125
batch: 33   train loss: 0.1931973099708557
batch: 34   train loss: 0.23488296568393707
batch: 35   train loss: 0.19431112706661224
batch: 36   train loss: 2.1901376247406006
batch: 37   train loss: 0.13117265701293945
batch: 38   train loss: 1.9685075283050537
batch: 39   train loss: 0.14971964061260223
batch: 40   train loss: 1.7779831886291504
batch: 41   train loss: 0.23471631109714508
batch: 42   train loss: 0.26271554827690125
batch: 43   train loss: 0.2751255929470062
batch: 44   train loss: 0.23998117446899414
batch: 45   train loss: 0.23671066761016846
batch: 46   train loss: 1.600120186805725
batch: 47   train loss: 1.4292882680892944
batch: 48   train loss: 1.206476092338562
batch: 49   train loss: 0.4341771900653839
batch: 50   train loss: 1.0067899227142334
batch: 51   train loss: 0.7236061096191406
batch: 52   train loss: 0.8268023729324341
batch: 53   train loss: 0.5260061025619507
batch: 54   train loss: 0.46292397379875183
batch: 55   train loss: 0.30917325615882874
batch: 56   train loss: 1.5907628536224365
batch: 57   train loss: 0.25887531042099
batch: 58   train loss: 2.02055287361145
batch: 59   train loss: 0.13755235075950623
batch: 60   train loss: 2.1245596408843994
batch: 61   train loss: 0.12943460047245026
batch: 62   train loss: 1.8543756008148193
batch: 63   train loss: 0.16608865559101105
batch: 64   train loss: 1.428985357284546
batch: 65   train loss: 0.20514550805091858
batch: 66   train loss: 1.4837429523468018
batch: 67   train loss: 1.395603895187378
batch: 68   train loss: 1.0917022228240967
batch: 69   train loss: 1.051458716392517
batch: 70   train loss: 0.799136221408844
batch: 71   train loss: 0.4847501516342163
batch: 72   train loss: 1.209062933921814
batch: 73   train loss: 1.150587558746338
batch: 74   train loss: 0.3150644302368164
batch: 75   train loss: 0.2575475871562958
batch: 76   train loss: 0.220547616481781
batch: 77   train loss: 1.6497406959533691
batch: 78   train loss: 1.66617751121521
batch: 79   train loss: 1.5987426042556763
batch: 80   train loss: 1.6336292028427124
batch: 81   train loss: 0.28537729382514954
batch: 82   train loss: 1.18588125705719
batch: 83   train loss: 0.347726970911026
batch: 84   train loss: 1.0719752311706543
batch: 85   train loss: 0.5741105675697327
batch: 86   train loss: 0.8917783498764038
batch: 87   train loss: 0.5829558968544006
batch: 88   train loss: 0.5097626447677612
batch: 89   train loss: 0.8889930844306946
batch: 90   train loss: 1.0478544235229492
batch: 91   train loss: 0.35029083490371704
batch: 92   train loss: 0.2908981740474701
batch: 93   train loss: 1.412675142288208
batch: 94   train loss: 1.3776512145996094
batch: 95   train loss: 1.1954606771469116
batch: 96   train loss: 0.46937015652656555
batch: 97   train loss: 0.9619700908660889
batch: 98   train loss: 0.839040994644165
batch: 99   train loss: 0.7104458808898926
batch: 100   train loss: 0.6107429265975952
batch: 101   train loss: 0.7274240255355835
batch: 102   train loss: 0.8794163465499878
batch: 103   train loss: 0.6508463025093079
batch: 104   train loss: 1.0272108316421509
batch: 105   train loss: 0.6993659734725952
batch: 106   train loss: 1.0098810195922852
batch: 107   train loss: 0.5230602025985718
batch: 108   train loss: 0.7434461116790771
batch: 109   train loss: 0.8418596386909485
batch: 110   train loss: 0.7570500373840332
batch: 111   train loss: 0.7472530603408813
batch: 112   train loss: 0.6305496096611023
batch: 113   train loss: 0.8590299487113953
batch: 114   train loss: 0.5264529585838318
batch: 115   train loss: 0.46179917454719543
batch: 116   train loss: 1.179521083831787
batch: 117   train loss: 0.3442707061767578
batch: 118   train loss: 1.299201488494873
batch: 119   train loss: 1.2713950872421265
batch: 120   train loss: 0.3411426544189453
batch: 121   train loss: 1.3567919731140137
batch: 122   train loss: 0.3080906569957733
batch: 123   train loss: 0.3179469406604767
batch: 124   train loss: 0.3254554867744446
batch: 125   train loss: 0.4259085953235626
batch: 126   train loss: 0.417072057723999
batch: 127   train loss: 0.32772696018218994
batch: 128   train loss: 0.2639816105365753
batch: 129   train loss: 0.22585545480251312
batch: 130   train loss: 0.3371798098087311
batch: 131   train loss: 1.3798496723175049
batch: 132   train loss: 0.2238272875547409
batch: 133   train loss: 1.6292304992675781
batch: 134   train loss: 1.799892544746399
batch: 135   train loss: 0.2830314338207245
batch: 136   train loss: 0.228107288479805
batch: 137   train loss: 1.7007291316986084
batch: 138   train loss: 1.3676193952560425
batch: 139   train loss: 1.330457329750061
batch: 140   train loss: 0.9583857655525208
batch: 141   train loss: 0.8542686104774475
batch: 142   train loss: 0.8691686391830444
batch: 143   train loss: 0.8796833753585815
batch: 144   train loss: 0.5336776375770569
batch: 145   train loss: 1.1068376302719116
batch: 146   train loss: 0.38587287068367004
batch: 147   train loss: 1.3139148950576782
batch: 148   train loss: 0.2864627540111542
batch: 149   train loss: 1.6025199890136719
batch: 150   train loss: 0.2560136318206787
batch: 151   train loss: 0.2619648873806
batch: 152   train loss: 1.5558785200119019
batch: 153   train loss: 0.26289328932762146
batch: 154   train loss: 1.5565073490142822
batch: 155   train loss: 1.3754090070724487
batch: 156   train loss: 0.3239772915840149
batch: 157   train loss: 1.1767323017120361
batch: 158   train loss: 0.4368089735507965
batch: 159   train loss: 0.505207896232605
batch: 160   train loss: 0.8655518293380737
batch: 161   train loss: 0.5760340094566345
batch: 162   train loss: 0.8294250965118408
batch: 163   train loss: 0.6595688462257385
batch: 164   train loss: 0.6758318543434143
batch: 165   train loss: 0.703617513179779
batch: 166   train loss: 0.7045930624008179
batch: 167   train loss: 0.6912932991981506
batch: 168   train loss: 0.7206773161888123
batch: 169   train loss: 0.6328573226928711
batch: 170   train loss: 0.809112012386322
batch: 171   train loss: 0.6329962611198425
batch: 172   train loss: 0.5939117670059204
batch: 173   train loss: 0.8840948939323425
batch: 174   train loss: 0.9027860164642334
batch: 175   train loss: 0.8494662046432495
batch: 176   train loss: 0.7512872219085693
batch: 177   train loss: 0.7222130298614502
batch: 178   train loss: 0.7982305884361267
batch: 179   train loss: 0.7611358165740967
batch: 180   train loss: 0.6653977632522583
batch: 181   train loss: 0.7742695212364197
batch: 182   train loss: 0.7184354066848755
batch: 183   train loss: 0.7380291223526001
batch: 184   train loss: 0.7474625110626221
batch: 185   train loss: 0.7378968000411987
batch: 186   train loss: 0.7252969145774841
batch: 187   train loss: 0.7153767347335815
batch: 188   train loss: 0.6934978365898132
batch: 189   train loss: 0.6863003969192505
batch: 190   train loss: 0.7228342294692993
batch: 191   train loss: 0.698151171207428
batch: 192   train loss: 0.6593837738037109
batch: 193   train loss: 0.7620973587036133
batch: 194   train loss: 0.7530896663665771
batch: 195   train loss: 0.6208535432815552
batch: 196   train loss: 0.7570104598999023
batch: 197   train loss: 0.6789675951004028
batch: 198   train loss: 0.7486424446105957
batch: 199   train loss: 0.7183780670166016
batch: 200   train loss: 0.6528913378715515
batch: 201   train loss: 0.5889924168586731
batch: 202   train loss: 0.9323670864105225
batch: 203   train loss: 0.957128643989563
batch: 204   train loss: 0.9568748474121094
batch: 205   train loss: 0.8884952068328857
batch: 206   train loss: 0.6174997091293335
batch: 207   train loss: 0.7292832732200623
batch: 208   train loss: 0.736341118812561
batch: 209   train loss: 0.6273640394210815
batch: 210   train loss: 0.5823222994804382
batch: 211   train loss: 0.5002622604370117
batch: 212   train loss: 1.039756417274475
batch: 213   train loss: 1.148905873298645
batch: 214   train loss: 1.1066995859146118
batch: 215   train loss: 0.44828903675079346
batch: 216   train loss: 0.49785616993904114
batch: 217   train loss: 0.48639243841171265
batch: 218   train loss: 0.44585320353507996
batch: 219   train loss: 0.4173598289489746
batch: 220   train loss: 0.38304486870765686
batch: 221   train loss: 0.29975998401641846
batch: 222   train loss: 0.2522965669631958
batch: 223   train loss: 1.7123292684555054
batch: 224   train loss: 0.19681835174560547
batch: 225   train loss: 1.805260419845581
batch: 226   train loss: 0.19642290472984314
batch: 227   train loss: 1.7192184925079346
batch: 228   train loss: 0.23013485968112946
batch: 229   train loss: 0.24558202922344208
batch: 230   train loss: 0.2587684690952301
batch: 231   train loss: 1.4496312141418457
batch: 232   train loss: 1.3984241485595703
batch: 233   train loss: 1.1848853826522827
batch: 234   train loss: 0.4504728317260742
batch: 235   train loss: 0.5281715393066406
batch: 236   train loss: 0.7988049387931824
batch: 237   train loss: 0.7105121612548828
batch: 238   train loss: 0.5876181125640869
batch: 239   train loss: 0.4773813486099243
batch: 240   train loss: 1.1756829023361206
batch: 241   train loss: 0.3202008903026581
batch: 242   train loss: 0.2850310802459717
batch: 243   train loss: 1.5575923919677734
batch: 244   train loss: 1.526606559753418
batch: 245   train loss: 0.2384670525789261
batch: 246   train loss: 0.24204817414283752
batch: 247   train loss: 1.433579683303833
batch: 248   train loss: 0.3072899281978607
batch: 249   train loss: 1.5050089359283447
batch: 250   train loss: 0.31837230920791626
batch: 251   train loss: 0.3604620099067688
batch: 252   train loss: 1.2055366039276123
batch: 253   train loss: 1.0578994750976562
batch: 254   train loss: 0.4247981607913971
batch: 255   train loss: 0.47097814083099365
batch: 256   train loss: 0.5908607244491577
batch: 257   train loss: 0.5253027081489563
batch: 258   train loss: 0.9873775243759155
batch: 259   train loss: 0.5030567646026611
batch: 260   train loss: 0.4805329740047455
batch: 261   train loss: 0.43909162282943726
batch: 262   train loss: 0.41940322518348694
batch: 263   train loss: 1.1472599506378174
batch: 264   train loss: 0.3522251546382904
batch: 265   train loss: 0.34592893719673157
batch: 266   train loss: 1.289067268371582
batch: 267   train loss: 1.360756516456604
batch: 268   train loss: 1.2489755153656006
batch: 269   train loss: 0.38606858253479004
batch: 270   train loss: 0.5072615146636963
batch: 271   train loss: 0.4613344669342041
batch: 272   train loss: 0.42712876200675964
batch: 273   train loss: 0.40535956621170044
batch: 274   train loss: 0.4181765615940094
batch: 275   train loss: 1.236714482307434
batch: 276   train loss: 1.212572693824768
batch: 277   train loss: 0.4454728662967682
batch: 278   train loss: 1.1444600820541382
batch: 279   train loss: 0.9260095953941345
batch: 280   train loss: 0.8327038884162903
batch: 281   train loss: 0.680700421333313
batch: 282   train loss: 0.7630605697631836
batch: 283   train loss: 0.7731597423553467
batch: 284   train loss: 0.6308217644691467
batch: 285   train loss: 0.6267746090888977
batch: 286   train loss: 0.57365882396698
batch: 287   train loss: 0.9020264148712158
batch: 288   train loss: 0.9547897577285767
batch: 289   train loss: 0.9419479966163635
batch: 290   train loss: 0.591484546661377
batch: 291   train loss: 0.6087720990180969
batch: 292   train loss: 0.8274862766265869
batch: 293   train loss: 0.7998577356338501
batch: 294   train loss: 0.7545274496078491
batch: 295   train loss: 0.656785786151886
batch: 296   train loss: 0.5573620200157166
batch: 297   train loss: 0.4836459755897522
batch: 298   train loss: 1.1318793296813965
batch: 299   train loss: 0.33496299386024475
batch: 300   train loss: 1.3740719556808472
batch: 301   train loss: 1.427525520324707
batch: 302   train loss: 0.29586946964263916
batch: 303   train loss: 0.3043871521949768
batch: 304   train loss: 1.4247300624847412
batch: 305   train loss: 0.28345128893852234
batch: 306   train loss: 0.30279839038848877
batch: 307   train loss: 1.3796402215957642
batch: 308   train loss: 1.1633433103561401
batch: 309   train loss: 0.35693979263305664
batch: 310   train loss: 1.1233265399932861
batch: 311   train loss: 0.48962754011154175
batch: 312   train loss: 0.946172833442688
batch: 313   train loss: 0.6160023808479309
batch: 314   train loss: 0.7708258628845215
batch: 315   train loss: 0.6650909185409546
batch: 316   train loss: 0.6388804316520691
batch: 317   train loss: 0.579980731010437
batch: 318   train loss: 0.45235303044319153
batch: 319   train loss: 0.36223769187927246
batch: 320   train loss: 0.26338598132133484
batch: 321   train loss: 0.2209021896123886
batch: 322   train loss: 1.797048568725586
batch: 323   train loss: 2.0306758880615234
batch: 324   train loss: 0.14512839913368225
batch: 325   train loss: 0.14399071037769318
batch: 326   train loss: 0.1385936141014099
batch: 327   train loss: 2.057077169418335
batch: 328   train loss: 1.9942961931228638
batch: 329   train loss: 1.9768774509429932
batch: 330   train loss: 1.887467622756958
batch: 331   train loss: 0.2267943173646927
batch: 332   train loss: 1.275071620941162
batch: 333   train loss: 0.3751620054244995
batch: 334   train loss: 0.49091488122940063
batch: 335   train loss: 0.5688719749450684
batch: 336   train loss: 0.604146420955658
batch: 337   train loss: 0.6345196962356567
batch: 338   train loss: 0.7925198078155518
batch: 339   train loss: 0.7732301950454712
batch: 340   train loss: 0.7296797037124634
batch: 341   train loss: 0.7102405428886414
batch: 342   train loss: 0.8241679668426514
batch: 343   train loss: 0.8911702632904053
batch: 344   train loss: 0.8769530057907104
batch: 345   train loss: 0.7815918922424316
batch: 346   train loss: 0.7844406366348267
batch: 347   train loss: 0.7029279470443726
batch: 348   train loss: 0.7428193688392639
batch: 349   train loss: 0.6117532849311829
batch: 350   train loss: 0.5600972175598145
batch: 351   train loss: 0.5103848576545715
batch: 352   train loss: 0.44094762206077576
batch: 353   train loss: 1.1698404550552368
batch: 354   train loss: 1.26304030418396
batch: 355   train loss: 1.2908954620361328
batch: 356   train loss: 1.2137444019317627
batch: 357   train loss: 0.3748966157436371
batch: 358   train loss: 0.39323389530181885
batch: 359   train loss: 1.1509604454040527
batch: 360   train loss: 1.0093650817871094
batch: 361   train loss: 0.457653671503067
batch: 362   train loss: 0.9465287327766418
batch: 363   train loss: 0.5204812288284302
batch: 364   train loss: 0.8577598333358765
batch: 365   train loss: 0.6304876804351807
batch: 366   train loss: 0.754997193813324
batch: 367   train loss: 0.7283021211624146
batch: 368   train loss: 0.6700679659843445
batch: 369   train loss: 0.6830182075500488
batch: 370   train loss: 0.6395055651664734
batch: 371   train loss: 0.7165826559066772
batch: 372   train loss: 0.6386175751686096
batch: 373   train loss: 0.783265233039856
batch: 374   train loss: 0.8257795572280884
batch: 375   train loss: 0.6879440546035767
batch: 376   train loss: 0.7213305830955505
batch: 377   train loss: 0.7431747913360596
batch: 378   train loss: 0.6873790621757507
batch: 379   train loss: 0.7120429277420044
batch: 380   train loss: 0.7954733967781067
batch: 381   train loss: 0.6920927166938782
batch: 382   train loss: 0.6305420994758606
batch: 383   train loss: 0.9107733964920044
batch: 384   train loss: 0.4907367527484894
batch: 385   train loss: 0.8845688104629517
batch: 386   train loss: 0.4893443286418915
batch: 387   train loss: 1.0058988332748413
batch: 388   train loss: 0.40823084115982056
batch: 389   train loss: 0.43179911375045776
batch: 390   train loss: 0.47468170523643494
batch: 391   train loss: 1.1107929944992065
batch: 392   train loss: 1.1269986629486084
batch: 393   train loss: 0.3593733310699463
batch: 394   train loss: 1.0749332904815674
batch: 395   train loss: 0.43590864539146423
batch: 396   train loss: 0.47596558928489685
batch: 397   train loss: 1.0334755182266235
batch: 398   train loss: 0.4072287976741791
batch: 399   train loss: 0.9483199119567871
batch: 400   train loss: 0.8834628462791443
batch: 401   train loss: 0.5150095820426941
batch: 402   train loss: 0.6139489412307739
batch: 403   train loss: 0.854535698890686
batch: 404   train loss: 0.89217209815979
batch: 405   train loss: 0.6356087327003479
batch: 406   train loss: 0.8708469867706299
batch: 407   train loss: 0.6192682385444641
batch: 408   train loss: 0.7089767456054688
batch: 409   train loss: 0.7123709917068481
batch: 410   train loss: 0.6856058835983276
batch: 411   train loss: 0.6398985981941223
batch: 412   train loss: 0.6688241362571716
batch: 413   train loss: 1.0123845338821411
batch: 414   train loss: 1.15944504737854
batch: 415   train loss: 0.5052177309989929
batch: 416   train loss: 0.4761500060558319
batch: 417   train loss: 1.1546025276184082
batch: 418   train loss: 1.1073721647262573
batch: 419   train loss: 1.0438487529754639
batch: 420   train loss: 0.5093317627906799
batch: 421   train loss: 0.5460655093193054
batch: 422   train loss: 0.574359655380249
batch: 423   train loss: 0.862119197845459
batch: 424   train loss: 0.8758963942527771
batch: 425   train loss: 0.6182504296302795
batch: 426   train loss: 0.8102161884307861
batch: 427   train loss: 0.6309958696365356
batch: 428   train loss: 0.7490628957748413
batch: 429   train loss: 0.6716350317001343
batch: 430   train loss: 0.8018501996994019
batch: 431   train loss: 0.5511879920959473
batch: 432   train loss: 0.8804447650909424
batch: 433   train loss: 0.8679325580596924
batch: 434   train loss: 0.5655633807182312
batch: 435   train loss: 0.590116560459137
batch: 436   train loss: 0.5235933065414429
batch: 437   train loss: 0.5209230184555054
batch: 438   train loss: 0.47133156657218933
batch: 439   train loss: 0.4294603765010834
batch: 440   train loss: 0.3821272552013397
batch: 441   train loss: 0.3072623014450073
batch: 442   train loss: 1.4121569395065308
batch: 443   train loss: 0.25918132066726685
batch: 444   train loss: 1.5770807266235352
batch: 445   train loss: 1.6087040901184082
batch: 446   train loss: 0.23269584774971008
batch: 447   train loss: 0.26629582047462463
batch: 448   train loss: 0.26227766275405884
batch: 449   train loss: 1.4454683065414429
batch: 450   train loss: 0.28627195954322815
batch: 451   train loss: 0.3139396011829376
batch: 452   train loss: 0.29647982120513916
batch: 453   train loss: 1.269525170326233
batch: 454   train loss: 1.3630404472351074
batch: 455   train loss: 0.3412259519100189
batch: 456   train loss: 1.211024522781372
batch: 457   train loss: 1.0647979974746704
batch: 458   train loss: 0.4398113191127777
batch: 459   train loss: 0.4914095997810364
batch: 460   train loss: 0.4933874309062958
batch: 461   train loss: 0.5203171372413635
batch: 462   train loss: 0.48375576734542847
batch: 463   train loss: 0.47720152139663696
batch: 464   train loss: 0.9585097432136536
batch: 465   train loss: 0.4636911451816559
batch: 466   train loss: 0.997153639793396
batch: 467   train loss: 0.9773790836334229
batch: 468   train loss: 0.49468672275543213
batch: 469   train loss: 0.5380225777626038
batch: 470   train loss: 0.5723252296447754
batch: 471   train loss: 0.9438470602035522
batch: 472   train loss: 0.912936806678772
batch: 473   train loss: 0.753859281539917
batch: 474   train loss: 0.5928547978401184
batch: 475   train loss: 0.584661066532135
batch: 476   train loss: 0.9061595797538757
batch: 477   train loss: 0.7464399933815002
batch: 478   train loss: 0.6370389461517334
batch: 479   train loss: 0.7321250438690186
batch: 480   train loss: 0.7356525659561157
batch: 481   train loss: 0.656734824180603
batch: 482   train loss: 0.7318569421768188
batch: 483   train loss: 0.8014573454856873
batch: 484   train loss: 0.7766021490097046
batch: 485   train loss: 0.7104182243347168
batch: 486   train loss: 0.6621412038803101
batch: 487   train loss: 0.6721540093421936
batch: 488   train loss: 0.6268674731254578
batch: 489   train loss: 0.5758983492851257
batch: 490   train loss: 0.5282038450241089
batch: 491   train loss: 0.4055609405040741
batch: 492   train loss: 1.2203550338745117
batch: 493   train loss: 1.085134744644165
batch: 494   train loss: 1.0945161581039429
batch: 495   train loss: 1.223210334777832
batch: 496   train loss: 1.0937402248382568
batch: 497   train loss: 1.1086452007293701
batch: 498   train loss: 0.45081982016563416
batch: 499   train loss: 0.5539940595626831
batch: 500   train loss: 0.5308515429496765
batch: 501   train loss: 0.503593385219574
batch: 502   train loss: 0.5697618722915649
batch: 503   train loss: 0.908420205116272
batch: 504   train loss: 0.876437783241272
batch: 505   train loss: 0.6135568022727966
batch: 506   train loss: 0.5544540882110596
batch: 507   train loss: 0.5355491638183594
batch: 508   train loss: 0.8772218823432922
batch: 509   train loss: 0.4849427044391632
batch: 510   train loss: 0.41371452808380127
batch: 511   train loss: 0.5374352335929871
batch: 512   train loss: 1.43361234664917
batch: 513   train loss: 0.9845402240753174
batch: 514   train loss: 0.9609440565109253
batch: 515   train loss: 0.4056510627269745
batch: 516   train loss: 0.9967659115791321
batch: 517   train loss: 0.4486468434333801
batch: 518   train loss: 0.5311103463172913
batch: 519   train loss: 0.42851102352142334
batch: 520   train loss: 0.5294066667556763
batch: 521   train loss: 0.47224152088165283
batch: 522   train loss: 0.3124152421951294
batch: 523   train loss: 1.451622486114502
batch: 524   train loss: 1.1474528312683105
batch: 525   train loss: 0.4282449781894684
batch: 526   train loss: 1.119792103767395
batch: 527   train loss: 0.34261998534202576
batch: 528   train loss: 1.2205349206924438
batch: 529   train loss: 0.4071570932865143
batch: 530   train loss: 0.5169702768325806
batch: 531   train loss: 0.8931495547294617
batch: 532   train loss: 0.5642989277839661
batch: 533   train loss: 0.937283992767334
batch: 534   train loss: 0.7731971144676208
batch: 535   train loss: 0.7421309351921082
batch: 536   train loss: 0.617415726184845
batch: 537   train loss: 0.9460328221321106
batch: 538   train loss: 0.9623779058456421
batch: 539   train loss: 0.4661963880062103
batch: 540   train loss: 0.44450023770332336
batch: 541   train loss: 0.36546263098716736
batch: 542   train loss: 1.0928840637207031
batch: 543   train loss: 0.300383597612381
batch: 544   train loss: 1.3302206993103027
batch: 545   train loss: 1.276073694229126
batch: 546   train loss: 1.2961283922195435
batch: 547   train loss: 0.30353522300720215
batch: 548   train loss: 0.4845062494277954
batch: 549   train loss: 0.4408581256866455
batch: 550   train loss: 1.0525580644607544
batch: 551   train loss: 0.4824310839176178
batch: 552   train loss: 0.4882238507270813
batch: 553   train loss: 0.9639099836349487
batch: 554   train loss: 0.5207387208938599
batch: 555   train loss: 0.9577194452285767
batch: 556   train loss: 0.5377304553985596
batch: 557   train loss: 0.8341013193130493
batch: 558   train loss: 0.5858699083328247
batch: 559   train loss: 0.5934340953826904
batch: 560   train loss: 0.5664530396461487
batch: 561   train loss: 0.5361025929450989
batch: 562   train loss: 0.9056806564331055
batch: 563   train loss: 0.8807568550109863
batch: 564   train loss: 0.8370007276535034
batch: 565   train loss: 0.86049485206604
batch: 566   train loss: 0.6241663694381714
batch: 567   train loss: 0.5491843819618225
batch: 568   train loss: 0.8096579909324646
batch: 569   train loss: 0.6232498288154602
batch: 570   train loss: 0.7427380681037903
batch: 571   train loss: 0.6614016890525818
batch: 572   train loss: 0.6363809704780579
batch: 573   train loss: 0.6075072884559631
batch: 574   train loss: 0.5531790256500244
batch: 575   train loss: 0.45331692695617676
batch: 576   train loss: 0.4070737659931183
batch: 577   train loss: 0.30375421047210693
batch: 578   train loss: 1.3884828090667725
batch: 579   train loss: 0.2852906584739685
batch: 580   train loss: 0.2181381732225418
batch: 581   train loss: 1.847854495048523
batch: 582   train loss: 1.6999412775039673
batch: 583   train loss: 0.20243090391159058
batch: 584   train loss: 0.19527505338191986
batch: 585   train loss: 0.20635317265987396
batch: 586   train loss: 0.20726826786994934
batch: 587   train loss: 1.7779103517532349
batch: 588   train loss: 1.7104980945587158
batch: 589   train loss: 0.23660501837730408
batch: 590   train loss: 1.4846346378326416
batch: 591   train loss: 1.4647603034973145
batch: 592   train loss: 0.3506781756877899
batch: 593   train loss: 0.5063714385032654
batch: 594   train loss: 1.0044039487838745
batch: 595   train loss: 0.48366737365722656
batch: 596   train loss: 0.6352761387825012
batch: 597   train loss: 0.6387621164321899
batch: 598   train loss: 0.5723069310188293
batch: 599   train loss: 0.6023476123809814
batch: 600   train loss: 0.53159099817276
batch: 601   train loss: 0.964759886264801
batch: 602   train loss: 0.9739981889724731
batch: 603   train loss: 0.48141199350357056
batch: 604   train loss: 0.9660376906394958
batch: 605   train loss: 0.46927395462989807
batch: 606   train loss: 0.4814888834953308
batch: 607   train loss: 1.017142653465271
batch: 608   train loss: 0.4788993000984192
batch: 609   train loss: 0.4563918113708496
batch: 610   train loss: 1.032249093055725
batch: 611   train loss: 1.1129555702209473
batch: 612   train loss: 0.4708990156650543
batch: 613   train loss: 0.9851223230361938
batch: 614   train loss: 0.8629379272460938
batch: 615   train loss: 0.5771217942237854
batch: 616   train loss: 0.5654232501983643
batch: 617   train loss: 0.731358528137207
batch: 618   train loss: 0.6731836199760437
batch: 619   train loss: 0.7259642481803894
batch: 620   train loss: 0.7185522317886353
batch: 621   train loss: 0.6908846497535706
batch: 622   train loss: 0.6662300825119019
batch: 623   train loss: 0.7035517692565918
batch: 624   train loss: 0.7351066470146179
batch: 625   train loss: 0.6640492677688599
batch: 626   train loss: 0.7476068735122681
batch: 627   train loss: 0.7514002323150635
batch: 628   train loss: 0.674001157283783
batch: 629   train loss: 0.674573540687561
batch: 630   train loss: 0.5922375917434692
batch: 631   train loss: 0.5092345476150513
batch: 632   train loss: 0.4625401198863983
batch: 633   train loss: 1.1241705417633057
batch: 634   train loss: 0.3434060215950012
batch: 635   train loss: 1.3237887620925903
batch: 636   train loss: 0.33319276571273804
batch: 637   train loss: 1.3754961490631104
batch: 638   train loss: 0.307740181684494
batch: 639   train loss: 1.5208853483200073
batch: 640   train loss: 0.33692869544029236
batch: 641   train loss: 1.2926971912384033
batch: 642   train loss: 1.174487590789795
batch: 643   train loss: 0.3800514340400696
batch: 644   train loss: 0.44822049140930176
batch: 645   train loss: 0.45075222849845886
batch: 646   train loss: 0.9986796379089355
batch: 647   train loss: 0.9504173994064331
batch: 648   train loss: 0.5371640920639038
batch: 649   train loss: 0.5618227124214172
batch: 650   train loss: 0.5738344192504883
batch: 651   train loss: 0.5726698637008667
batch: 652   train loss: 0.5554618239402771
batch: 653   train loss: 0.9045340418815613
batch: 654   train loss: 0.5003722906112671
batch: 655   train loss: 0.9805586934089661
batch: 656   train loss: 0.463547021150589
batch: 657   train loss: 0.9622353911399841
batch: 658   train loss: 0.4451773166656494
batch: 659   train loss: 0.4464816451072693
batch: 660   train loss: 1.0091426372528076
batch: 661   train loss: 0.43086397647857666
batch: 662   train loss: 0.47372356057167053
batch: 663   train loss: 0.9927033185958862
batch: 664   train loss: 0.44494909048080444
batch: 665   train loss: 0.4577844738960266
batch: 666   train loss: 0.37888503074645996
batch: 667   train loss: 0.3658154308795929
batch: 668   train loss: 0.299616277217865
batch: 669   train loss: 0.34039679169654846
batch: 670   train loss: 1.4620002508163452
batch: 671   train loss: 0.2947259247303009
batch: 672   train loss: 0.2294503003358841
batch: 673   train loss: 0.2658389210700989
batch: 674   train loss: 1.5227863788604736
batch: 675   train loss: 0.22193069756031036
batch: 676   train loss: 1.7042362689971924
batch: 677   train loss: 1.492203950881958
batch: 678   train loss: 0.26956015825271606
batch: 679   train loss: 0.2680392265319824
batch: 680   train loss: 1.3664436340332031
batch: 681   train loss: 0.3354688286781311
batch: 682   train loss: 1.283081293106079
batch: 683   train loss: 0.3956138491630554
batch: 684   train loss: 1.004728078842163
batch: 685   train loss: 0.46253079175949097
batch: 686   train loss: 0.9984108209609985
batch: 687   train loss: 0.5121744275093079
batch: 688   train loss: 0.772819995880127
batch: 689   train loss: 0.6013420224189758
batch: 690   train loss: 0.7374728918075562
batch: 691   train loss: 0.6433687210083008
batch: 692   train loss: 0.6137481331825256
batch: 693   train loss: 0.8852666616439819
batch: 694   train loss: 0.527396559715271
batch: 695   train loss: 0.4090202748775482
batch: 696   train loss: 1.021345853805542
batch: 697   train loss: 0.40982040762901306
batch: 698   train loss: 1.2477610111236572
batch: 699   train loss: 0.3362042307853699
batch: 700   train loss: 0.33807888627052307
batch: 701   train loss: 0.29857775568962097
batch: 702   train loss: 1.2663441896438599
batch: 703   train loss: 0.2592563033103943
batch: 704   train loss: 1.3622119426727295
batch: 705   train loss: 0.2922162711620331
batch: 706   train loss: 1.377771019935608
batch: 707   train loss: 0.2837141454219818
batch: 708   train loss: 1.1891539096832275
batch: 709   train loss: 0.3414898216724396
batch: 710   train loss: 0.40922409296035767
batch: 711   train loss: 0.9937727451324463
batch: 712   train loss: 0.45465099811553955
batch: 713   train loss: 0.9481902122497559
batch: 714   train loss: 0.4763644337654114
batch: 715   train loss: 0.5008376836776733
batch: 716   train loss: 0.6508397459983826
batch: 717   train loss: 0.41306206583976746
batch: 718   train loss: 1.0546703338623047
batch: 719   train loss: 0.8740451335906982
batch: 720   train loss: 0.4009414613246918
batch: 721   train loss: 0.8552777767181396
batch: 722   train loss: 0.9720060229301453
batch: 723   train loss: 1.0243675708770752
batch: 724   train loss: 0.5447534918785095
batch: 725   train loss: 0.9028895497322083
batch: 726   train loss: 0.6118262410163879
batch: 727   train loss: 0.8072174191474915
batch: 728   train loss: 0.68879634141922
batch: 729   train loss: 0.3796597421169281
batch: 730   train loss: 0.633346676826477
batch: 731   train loss: 0.8693833947181702
batch: 732   train loss: 0.24146172404289246
batch: 733   train loss: 1.6659789085388184
batch: 734   train loss: 1.6443979740142822
batch: 735   train loss: 0.24943362176418304
batch: 736   train loss: 1.4321889877319336
batch: 737   train loss: 0.3297532796859741
batch: 738   train loss: 1.1734870672225952
batch: 739   train loss: 1.011111855506897
batch: 740   train loss: 0.8076527714729309
batch: 741   train loss: 0.7895642518997192
batch: 742   train loss: 0.8828704953193665
batch: 743   train loss: 0.5294618606567383
batch: 744   train loss: 0.48900681734085083
batch: 745   train loss: 0.42858588695526123
batch: 746   train loss: 1.1955018043518066
batch: 747   train loss: 0.3451617658138275
batch: 748   train loss: 0.31738582253456116
batch: 749   train loss: 1.402358055114746
batch: 750   train loss: 0.2845172882080078
batch: 751   train loss: 0.2759610116481781
batch: 752   train loss: 1.477002501487732
batch: 753   train loss: 1.4315043687820435
batch: 754   train loss: 0.31462007761001587
batch: 755   train loss: 0.34240230917930603
batch: 756   train loss: 1.2069473266601562
batch: 757   train loss: 1.1158480644226074
batch: 758   train loss: 0.9856715202331543
batch: 759   train loss: 0.5681692361831665
batch: 760   train loss: 0.7471293210983276
batch: 761   train loss: 0.7451519966125488
batch: 762   train loss: 0.8075087070465088
batch: 763   train loss: 0.5760678052902222
batch: 764   train loss: 0.8735554814338684
batch: 765   train loss: 0.5388704538345337
batch: 766   train loss: 0.9072115421295166
batch: 767   train loss: 0.5264713168144226
batch: 768   train loss: 0.5150662660598755
batch: 769   train loss: 0.9542304873466492
batch: 770   train loss: 0.48913830518722534
batch: 771   train loss: 0.9738796353340149
batch: 772   train loss: 0.9504952430725098
batch: 773   train loss: 0.5303383469581604
batch: 774   train loss: 0.5492947697639465
batch: 775   train loss: 0.8658279180526733
batch: 776   train loss: 0.5711336731910706
batch: 777   train loss: 0.8303186893463135
batch: 778   train loss: 0.602130651473999
batch: 779   train loss: 0.6058356761932373
batch: 780   train loss: 0.8130335807800293
batch: 781   train loss: 0.5964506268501282
batch: 782   train loss: 0.8165344595909119
batch: 783   train loss: 0.5992682576179504
batch: 784   train loss: 0.8066970109939575
batch: 785   train loss: 0.7819738388061523
batch: 786   train loss: 0.6587987542152405
batch: 787   train loss: 0.6766478419303894
batch: 788   train loss: 0.7208487391471863
batch: 789   train loss: 0.6844478249549866
batch: 790   train loss: 0.674139678478241
batch: 791   train loss: 0.6394711136817932
batch: 792   train loss: 0.5867089629173279
batch: 793   train loss: 0.8983674049377441
batch: 794   train loss: 0.9410598278045654
batch: 795   train loss: 0.9406746625900269
batch: 796   train loss: 0.902239203453064
batch: 797   train loss: 0.5698468685150146
batch: 798   train loss: 0.5968422293663025
batch: 799   train loss: 0.7947409749031067
batch: 800   train loss: 0.630042314529419
batch: 801   train loss: 0.6346529722213745
batch: 802   train loss: 0.7756332159042358
batch: 803   train loss: 0.6259703636169434
batch: 804   train loss: 0.7805126905441284
batch: 805   train loss: 0.7655626535415649
batch: 806   train loss: 0.7248920798301697
batch: 807   train loss: 0.7223244905471802
batch: 808   train loss: 0.7521026134490967
batch: 809   train loss: 0.6378132104873657
batch: 810   train loss: 0.7759621739387512
batch: 811   train loss: 0.622162401676178
batch: 812   train loss: 0.7880939245223999
batch: 813   train loss: 0.7761324644088745
batch: 814   train loss: 0.6500510573387146
batch: 815   train loss: 0.6589080691337585
batch: 816   train loss: 0.644913375377655
batch: 817   train loss: 0.6116378307342529
batch: 818   train loss: 0.563814640045166
batch: 819   train loss: 0.5065553784370422
batch: 820   train loss: 1.0246540307998657
batch: 821   train loss: 0.4153558611869812
batch: 822   train loss: 1.1527820825576782
batch: 823   train loss: 1.1727360486984253
batch: 824   train loss: 1.1431704759597778
batch: 825   train loss: 1.0731498003005981
batch: 826   train loss: 0.4738580584526062
batch: 827   train loss: 0.9128373265266418
batch: 828   train loss: 0.830016553401947
batch: 829   train loss: 0.6523728966712952
batch: 830   train loss: 0.6792958974838257
batch: 831   train loss: 0.7798514366149902
batch: 832   train loss: 0.8207883834838867
batch: 833   train loss: 0.8282650113105774
batch: 834   train loss: 0.804196834564209
batch: 835   train loss: 0.6287577748298645
batch: 836   train loss: 0.7496790885925293
batch: 837   train loss: 0.722809910774231
batch: 838   train loss: 0.7026616930961609
batch: 839   train loss: 0.6687049269676208
batch: 840   train loss: 0.6385297775268555
batch: 841   train loss: 0.802614688873291
batch: 842   train loss: 0.5775191783905029
batch: 843   train loss: 0.546231210231781
batch: 844   train loss: 0.503311812877655
batch: 845   train loss: 0.45216304063796997
batch: 846   train loss: 0.39700329303741455
batch: 847   train loss: 1.239797830581665
batch: 848   train loss: 1.2964622974395752
batch: 849   train loss: 1.291007399559021
batch: 850   train loss: 0.34319740533828735
batch: 851   train loss: 1.2089645862579346
batch: 852   train loss: 0.3836921751499176
batch: 853   train loss: 1.1067754030227661
batch: 854   train loss: 0.4361788034439087
batch: 855   train loss: 1.0011252164840698
batch: 856   train loss: 0.4964977204799652
batch: 857   train loss: 0.9024489521980286
batch: 858   train loss: 0.8467245101928711
batch: 859   train loss: 0.6155784726142883
batch: 860   train loss: 0.6517707705497742
batch: 861   train loss: 0.6681672930717468
batch: 862   train loss: 0.7209879755973816
batch: 863   train loss: 0.7050342559814453
batch: 864   train loss: 0.6740549206733704
batch: 865   train loss: 0.6313531398773193
batch: 866   train loss: 0.5799533724784851
batch: 867   train loss: 0.5229478478431702
batch: 868   train loss: 0.46318066120147705
batch: 869   train loss: 0.4030643701553345
batch: 870   train loss: 1.2319811582565308
batch: 871   train loss: 1.303379774093628
batch: 872   train loss: 0.31176838278770447
batch: 873   train loss: 0.300811231136322
batch: 874   train loss: 1.3937458992004395
batch: 875   train loss: 1.3815921545028687
batch: 876   train loss: 0.31018945574760437
batch: 877   train loss: 0.32329636812210083
batch: 878   train loss: 1.2728848457336426
batch: 879   train loss: 0.3504910171031952
batch: 880   train loss: 1.1885285377502441
batch: 881   train loss: 0.3916812539100647
batch: 882   train loss: 0.40965694189071655
batch: 883   train loss: 0.41781774163246155
batch: 884   train loss: 0.4172501862049103
batch: 885   train loss: 0.4090367555618286
batch: 886   train loss: 1.1212565898895264
batch: 887   train loss: 0.39627793431282043
batch: 888   train loss: 1.1284087896347046
batch: 889   train loss: 1.108282208442688
batch: 890   train loss: 0.4237697720527649
batch: 891   train loss: 1.037858247756958
batch: 892   train loss: 0.9938532710075378
batch: 893   train loss: 0.49657759070396423
batch: 894   train loss: 0.9045923948287964
batch: 895   train loss: 0.8614266514778137
batch: 896   train loss: 0.8121330738067627
batch: 897   train loss: 0.6309240460395813
batch: 898   train loss: 0.6620590090751648
batch: 899   train loss: 0.680552065372467
batch: 900   train loss: 0.6873342394828796
batch: 901   train loss: 0.6837561130523682
batch: 902   train loss: 0.7165313959121704
batch: 903   train loss: 0.6689359545707703
batch: 904   train loss: 0.7310759425163269
batch: 905   train loss: 0.6609998345375061
batch: 906   train loss: 0.7427375912666321
batch: 907   train loss: 0.6549625396728516
batch: 908   train loss: 0.7378137111663818
batch: 909   train loss: 0.7300991415977478
batch: 910   train loss: 0.7127875685691833
batch: 911   train loss: 0.6984347701072693
batch: 912   train loss: 0.6757262945175171
batch: 913   train loss: 0.7325833439826965
batch: 914   train loss: 0.6471709609031677
batch: 915   train loss: 0.7602158188819885
batch: 916   train loss: 0.6261112689971924
batch: 917   train loss: 0.6127941012382507
batch: 918   train loss: 0.5914137959480286
batch: 919   train loss: 0.5631136894226074
batch: 920   train loss: 0.8893760442733765
batch: 921   train loss: 0.5117937326431274
batch: 922   train loss: 0.4878598749637604
batch: 923   train loss: 0.45861542224884033
batch: 924   train loss: 1.0600231885910034
batch: 925   train loss: 0.4104677736759186
batch: 926   train loss: 0.3903687000274658
batch: 927   train loss: 0.3661501705646515
batch: 928   train loss: 0.3388788104057312
batch: 929   train loss: 1.3229701519012451
batch: 930   train loss: 1.3517141342163086
batch: 931   train loss: 0.3048698306083679
batch: 932   train loss: 0.30459102988243103
batch: 933   train loss: 1.352132797241211
batch: 934   train loss: 1.3259878158569336
batch: 935   train loss: 0.3307468295097351
batch: 936   train loss: 1.23020601272583
batch: 937   train loss: 1.1682379245758057
batch: 938   train loss: 1.0893771648406982
batch: 939   train loss: 0.4577861428260803
batch: 940   train loss: 0.9408548474311829
batch: 941   train loss: 0.8735311031341553
batch: 942   train loss: 0.8036957383155823
batch: 943   train loss: 0.6535632610321045
batch: 944   train loss: 0.6988475322723389
Epoch: 0   train loss: 0.6988475322723389
Traceback (most recent call last):
  File "/home/lyj/DeepLearning/ImageClassification/human_VS_ai/train.py", line 47, in <module>
    torch.save(model.state_dict(), 'epoch'+epoch+'.pth')
TypeError: can only concatenate str (not "int") to str
